{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KD9n4ypYYOMj"
      },
      "outputs": [],
      "source": [
        "!mkdir data\n",
        "import os\n",
        "for i in range(10):\n",
        "  os.system(f'wget https://cernbox.cern.ch/remote.php/dav/public-files/YQxujEYrVFFpylN/batch_1_{i}.tar.gz')\n",
        "  os.system(f'tar -xzf /content/batch_1_{i}.tar.gz')\n",
        "  os.system(f'cp ./batch_1_{i}/*.pt ./data')\n",
        "  os.system(f'rm -rf batch_1_{i}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Cj2VPmhrQJl",
        "outputId": "0329daf4-5cac-42b2-ce5d-38faadad7a4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.1+cu116\n",
            "11.6\n"
          ]
        }
      ],
      "source": [
        "!python -c \"import torch; print(torch.__version__)\"\n",
        "!python -c \"import torch; print(torch.version.cuda)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "94qRB7R9fRza",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8a443b63-1228-4a8f-8928-7e796667d2ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.13.1+1.6.html\n",
            "Collecting torch-scatter\n",
            "  Downloading torch_scatter-2.1.0.tar.gz (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 KB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.1.0-cp39-cp39-linux_x86_64.whl size=485242 sha256=03643edd0e560c142361491b2fd6b1aa898af32a5330eb79107d8ed7e37b1a81\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/33/3c/b02defb8e41252b9073b3b98433e082a8fb9aa8945127ffcbe\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.13.1+1.6.html\n",
            "Collecting torch-sparse\n",
            "  Downloading torch_sparse-0.6.16.tar.gz (208 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.2/208.2 KB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from torch-sparse) (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.9/dist-packages (from scipy->torch-sparse) (1.22.4)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.16-cp39-cp39-linux_x86_64.whl size=1083302 sha256=7d0391ca76ea7eb31d9c86c17acfc9ab457a6eb2284b91c344baac934be8fbbc\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/f3/e7/dfe620cda3bd0fabb2b5537548e53314539b4dd2d0a9eee06f\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.16\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.13.1+1.6.html\n",
            "Collecting torch-cluster\n",
            "  Downloading torch_cluster-1.6.0.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 KB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: torch-cluster\n",
            "  Building wheel for torch-cluster (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-cluster: filename=torch_cluster-1.6.0-cp39-cp39-linux_x86_64.whl size=657526 sha256=469eaebadabea957947ed19a2068891746f81b23f92bfb55904c20e4770aa52a\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/a2/33/54bd95e6b4bab10e078868a7853bf6e80c3c4442aef9ed322f\n",
            "Successfully built torch-cluster\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.13.1+1.6.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading torch_spline_conv-1.2.1.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: torch-spline-conv\n",
            "  Building wheel for torch-spline-conv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-spline-conv: filename=torch_spline_conv-1.2.1-cp39-cp39-linux_x86_64.whl size=200769 sha256=3789c19db4635a568be74ceb98b043ce71f32f8181a234fb2f54e7970fad1637\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/da/ed/5891164ace7209c85f9a2eaae7f6311d3d48aa44ab313c8a2a\n",
            "Successfully built torch-spline-conv\n",
            "Installing collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.2.0.tar.gz (564 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.0/565.0 KB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (2.25.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.2.1)\n",
            "Collecting psutil>=5.8.0\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 KB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch-geometric) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (2022.12.7)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.2.0-py3-none-any.whl size=773302 sha256=a9d8b468dc715449b69580846f5ec8e632c3f9ca6ff036d3bd90b8c458f020aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/b2/8c/9b4bb72a4384eabd1ffeab2b7ead692c9165e35711f8a9dc72\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: psutil, torch-geometric\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "Successfully installed psutil-5.9.4 torch-geometric-2.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.13.1+$11.6.html\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.13.1+$11.6.html\n",
        "!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-1.13.1+$11.6.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.13.1+$11.6.html\n",
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oRQjY6Gm-HvN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "BATCH_SIZE=32\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MVRcBIYYfHKi"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset  # not the one from PyG!\n",
        "from torch_geometric.loader import DataLoader\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "  def __init__(self, path: Path, lists:bool=False, data:list=[]):\n",
        "    super().__init__()\n",
        "    if lists:\n",
        "      self.graphs = data\n",
        "    else:\n",
        "      self.graphs = list(path.glob(\"*.pt\"))\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return torch.load(self.graphs[idx]).to(device)\n",
        "  \n",
        "  def __len__(self) -> int:\n",
        "    return len(self.graphs)\n",
        "\n",
        "data=list(Path('./data').glob('*.pt'))\n",
        "train,test = train_test_split(data,train_size=0.8)\n",
        "\n",
        "dataset = MyDataset(Path(\"./data\"))\n",
        "trainset = MyDataset('', True, train)\n",
        "testset = MyDataset('', True, test)\n",
        "loader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
        "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE)\n",
        "testloader = DataLoader(testset, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TXonS90Edm8l"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MBRCqBMn26eD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a24cc3a-a66d-405d-fe54-4dd94e8c21fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[176, 6], edge_index=[2, 1270], edge_attr=[1270, 4], y=[1270])\n",
            "tensor([[ 0.1454, -0.2843, -1.5020, -3.0306,  4.3126, -5.3583],\n",
            "        [ 0.1583, -0.2856, -1.5020, -2.9458,  3.9399, -4.9366],\n",
            "        [ 0.1462, -0.2862, -1.5020, -3.0254,  4.2574, -5.3560],\n",
            "        ...,\n",
            "        [ 0.1311, -0.2866,  1.5020,  3.1333,  4.7371, -5.9755],\n",
            "        [ 0.1713, -0.2358,  1.4980,  2.8648,  4.3074, -3.9400],\n",
            "        [ 0.1718, -0.2358,  1.5020,  2.8647,  4.2954, -3.9291]])\n",
            "tensor([[  0,   0,   1,  ..., 175, 174, 175],\n",
            "        [  4,   5,   6,  ..., 169, 170, 170]])\n",
            "tensor([[-0.0198, -0.0008,  0.2000,  0.0042],\n",
            "        [-0.0189, -0.0022,  0.2000,  0.0080],\n",
            "        [-0.0202, -0.0011,  0.2000,  0.0071],\n",
            "        ...,\n",
            "        [-0.0245,  0.0017, -0.2040,  0.0094],\n",
            "        [-0.0235,  0.0016, -0.1960,  0.0091],\n",
            "        [-0.0240,  0.0016, -0.2000,  0.0092]])\n",
            "tensor([1., 0., 1.,  ..., 1., 1., 1.])\n"
          ]
        }
      ],
      "source": [
        "print(trainset[0])\n",
        "print(trainset[0].x)\n",
        "print(trainset[0].edge_index)\n",
        "print(trainset[0].edge_attr)\n",
        "print(trainset[0].y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0q7shPNRL2bh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.nn as pyg_nn\n",
        "import torch_geometric.utils as pyg_utils\n",
        "from torch_geometric.utils import negative_sampling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_printoptions(linewidth=200)\n"
      ],
      "metadata": {
        "id": "Hdt8fKAk9Cse"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "FsnV4mTuLpDL"
      },
      "outputs": [],
      "source": [
        "class GNNStack(nn.Module):\n",
        "  def __init__(self,input_dim:int,hidden_dim:int,output_dim:int,num_edge_feat,layers:int,dropout:bool=False):\n",
        "    super(GNNStack,self).__init__()\n",
        "    self.dropout = dropout\n",
        "    self.layers = layers\n",
        "    self.convs = nn.ModuleList()\n",
        "    # nn.Linear(num_edge_feat,input_dim*hidden_dim)\n",
        "    self.convs.append(pyg_nn.NNConv(input_dim,hidden_dim,nn.Sequential(nn.Linear(num_edge_feat, 32), nn.ReLU(),nn.Linear(32, input_dim * hidden_dim))))\n",
        "    if layers>1:\n",
        "      for i in range(layers-1):\n",
        "        self.convs.append(pyg_nn.NNConv(hidden_dim,hidden_dim,nn.Sequential(nn.Linear(num_edge_feat, 32), nn.ReLU(),nn.Linear(32, hidden_dim * hidden_dim))))\n",
        "    self.post_conv = nn.Sequential(nn.Linear(hidden_dim,hidden_dim),nn.Dropout(self.dropout*0.5),nn.Linear(hidden_dim,output_dim))\n",
        "\n",
        "  def forward(self,x,edge_index,edge_attr):\n",
        "    for i in range(len(self.convs)):\n",
        "      x = self.convs[i](x,edge_index,edge_attr)\n",
        "      x = F.relu(x)\n",
        "      x = F.dropout(x, self.dropout*0.5,training= self.training)\n",
        "      # print(f'stage{i}',x)\n",
        "    x = self.post_conv(x)\n",
        "    # print(x,x.size())\n",
        "    return x\n",
        "\n",
        "  def predict_link(self,x,edge_index):\n",
        "    # print('pred link',edge_index[0],edge_index[1],edge_index[1].size())\n",
        "    # print(x[edge_index[0]],x[edge_index[0]].size(),x[edge_index[1]].size())\n",
        "    # print('link',(x[edge_index[0]]*x[edge_index[1]]).sum(dim=-1).size())\n",
        "    ret = (x[edge_index[0]]*x[edge_index[1]]).sum(dim=-1)\n",
        "    # ret = (10*ret)/torch.max(ret)\n",
        "    return ret\n",
        "\n",
        "  def loss(self, prediction, label):\n",
        "    return F.nll_loss(prediction, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "1yuHP6_1S0Ls"
      },
      "outputs": [],
      "source": [
        "def train(model, trainset, optim, criterion):\n",
        "\n",
        "  model.train()\n",
        "  optim.zero_grad()\n",
        "  train_losses = []\n",
        "  for i in range(len(trainset)):\n",
        "    neg_edge_index = negative_sampling(edge_index=trainset[i].edge_index, num_nodes=trainset[i].num_nodes,\n",
        "                                        num_neg_samples=trainset[i].edge_index.size(1),method='sparse')\n",
        "    # print('nei',neg_edge_index,neg_edge_index.size())\n",
        "    edge_index = torch.cat([trainset[i].edge_index,neg_edge_index],dim=-1)\n",
        "    y = torch.cat([trainset[i].y,trainset[i].y.new_zeros(neg_edge_index.size(1))],dim=0)\n",
        "\n",
        "    z= model.forward(trainset[i].x,trainset[i].edge_index,trainset[i].edge_attr)\n",
        "    # print('z',z)\n",
        "    # print('y',y,y.size())\n",
        "    # print(edge_index,edge_index.size(),trainset[i].edge_index.size())\n",
        "    out = model.predict_link(z,edge_index).view(-1)\n",
        "    # print(out,y)\n",
        "    loss = criterion(out, y)\n",
        "    train_losses.append(loss)\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "  # print(sum(train_losses)/len(train_losses))\n",
        "  return sum(train_losses)/len(train_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "TXLbcJWXFEsj"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "model = GNNStack(input_dim=trainset[0].num_features,hidden_dim=32,output_dim=16,num_edge_feat=trainset[0].num_edge_features,layers=1).to(device)\n",
        "optim = torch.optim.Adam(params=model.parameters(),lr=0.01)\n",
        "criterion = nn.BCEWithLogitsLoss() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "mpyviePKCSrI"
      },
      "outputs": [],
      "source": [
        "def test(model,testset):\n",
        "  model.eval()\n",
        "  test_scores=[]\n",
        "  for i in range(len(testset)):\n",
        "    neg_edge_index = negative_sampling(edge_index=testset[i].edge_index, num_nodes=testset[i].num_nodes,\n",
        "                                        num_neg_samples=testset[i].edge_index.size(1),method='sparse')\n",
        "    edge_index = torch.cat([testset[i].edge_index,neg_edge_index],dim=-1)\n",
        "    y = torch.cat([testset[i].y,testset[i].y.new_zeros(neg_edge_index.size(1))],dim=0)\n",
        "    z = model.forward(testset[i].x,testset[i].edge_index,testset[i].edge_attr)\n",
        "    out = model.predict_link(z, edge_index).view(-1)\n",
        "    out = out.sigmoid().cpu().detach().numpy()\n",
        "    # print(out)\n",
        "    score = roc_auc_score(y.cpu().numpy(),out)\n",
        "    test_scores.append(score)\n",
        "  return sum(test_scores)/len(test_scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQ4pAAXpv79z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccf7b1c4-4056-4226-cbb1-9274a5053bbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST SCORE : 0.5442800768680849\n",
            "Epoch : 1 && Loss : 71009566720000.0\n",
            "TEST SCORE : 0.5531904901984002\n",
            "Epoch : 2 && Loss : 358806097756160.0\n",
            "TEST SCORE : 0.5622923873232001\n",
            "Epoch : 3 && Loss : 1792183283744768.0\n",
            "TEST SCORE : 0.5370337274713081\n",
            "Epoch : 4 && Loss : 1.2711700889337856e+16\n",
            "TEST SCORE : 0.5906880691280794\n",
            "Epoch : 5 && Loss : 1.2352412916383744e+16\n",
            "TEST SCORE : 0.5788750604913461\n",
            "Epoch : 6 && Loss : 2678333015851008.0\n",
            "TEST SCORE : 0.5709006796961377\n",
            "Epoch : 7 && Loss : 1530734800011264.0\n",
            "TEST SCORE : 0.554165030681634\n",
            "Epoch : 8 && Loss : 467201073086464.0\n",
            "TEST SCORE : 0.5612070959193792\n",
            "Epoch : 9 && Loss : 726827584716800.0\n",
            "TEST SCORE : 0.5644180652875768\n",
            "Epoch : 10 && Loss : 377436659253248.0\n",
            "TEST SCORE : 0.5606523606563377\n",
            "Epoch : 11 && Loss : 231702395879424.0\n",
            "TEST SCORE : 0.5656267234168095\n",
            "Epoch : 12 && Loss : 98444928614400.0\n",
            "TEST SCORE : 0.5492814674400196\n",
            "Epoch : 13 && Loss : 31400885485568.0\n",
            "TEST SCORE : 0.5243942341445741\n",
            "Epoch : 14 && Loss : 10292578746368.0\n",
            "TEST SCORE : 0.517284236314288\n",
            "Epoch : 15 && Loss : 5282200551424.0\n",
            "TEST SCORE : 0.5550018375610054\n",
            "Epoch : 16 && Loss : 3621861457920.0\n",
            "TEST SCORE : 0.5468737763695378\n",
            "Epoch : 17 && Loss : 5738926178304.0\n"
          ]
        }
      ],
      "source": [
        "train_scores=[]\n",
        "test_scores=[]\n",
        "for epoch in range(1,101):\n",
        "  loss = train(model,trainset,optim,criterion)\n",
        "  train_scores.append(loss)\n",
        "  if epoch%1==0:\n",
        "    test_score=test(model,testset)\n",
        "    test_scores.append(test_score)\n",
        "    print(f'TEST SCORE : {test_score}')\n",
        "  print(f'Epoch : {epoch} && Loss : {loss}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}